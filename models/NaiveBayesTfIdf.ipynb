{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     class                                               text\n0       no  i'll  buy  the  iphone   x  if it can  get  ac...\n1       no  Some dude in FB selling the  iPhone   X  64 gb...\n2      yes  Home dab emote man today and I  get  hopped on...\n3      yes                               Buy  an  iPhone   X \n4       no  I hate iOS 11. My  iPhone  6+ works 10X slower...\n7       no  Bo-go sale tomorrow at T-Mobile  buy  one  get...\n8      yes  I can  get  the  iPhone   X  here.... If I'm w...\n9      yes  When you  buy  an  Iphone   X  with Unlimited ...\n10     yes  @ Mrwhosetheboss  i really  wish  i  get  to m...\n11      no  @ sprint  @sprintcare  if I switch to @TMobile...\n12      no  Oneplus 5t has faster face recognition than  i...\n13      no  Don't  buy  an  iPhone   X  if you're ugly. I ...\n14      no  Could  buy  2x 5T with the price I paid for th...\n15     yes  My friend shopping:  iPhone   X  is not that e...\n16     yes  What if there was upgrade to an  iPhone  8 or ...\n19      no  I don't  get  it is it basically impossible to...\n20     yes  The  iPhone   X  is a pleasure to use. Far mor...\n22      no  I wanted the  IPhone   X  but now that most pl...\n23     yes  I  love  these holiday gift guides that assume...\n24     yes  VIP  NEED   BUY  AN  IPHONE   X   https:// twi...\n27      no  Anyone else experiencing an  iPhone  glitch wh...\n29     yes  Need  to just  buy  that  iPhone   X  so I can...\n30     yes  Apple just send me an email with Christmas gif...\n32     yes                               Buy  an  iPhone   X \n33     yes                              Love  the Design.... \n34      no  u can  buy  yourself an  iPhone   X  but can n...\n35     yes  I  love  my Note 8 its been an  awesome  phone...\n36      no                             Not this what i want  \n37      no  In crazy  love  with this video!!! Don't  Buy ...\n39     yes                 So in  love   w  the  iPhone   x .\n...    ...                                                ...\n1296    no  Im an Apple fanboy and I never thought I would...\n1297    no  So the  iPhone   X  is not  like  the letter i...\n1299   yes                  I'm gonna  buy  the  iPhone   X .\n1300   yes                     iPhone   X  brightness is good\n1303   yes  Got notified this morning my card was charged ...\n1306   yes  Had some hands-on time with a friend’s  iPhone...\n1307   yes                 i  need  my  iphone   x  to ship !\n1309    no  fucked up by messing with the  iphone   x  at ...\n1310   yes  The executive summary of this  iPhone   X  Dia...\n1311   yes                          I  need  that  iPhone   X\n1314   yes  Trying to  get  use to my  iPhone   X .  Wish ...\n1316   yes  Went to  get  the  iPhone   X  today but after...\n1317   yes  I just justified the  purchase  of this  iPhon...\n1318    no   I’m not upgrading to shit but that  iPhone   X .\n1319   yes  some kid walked into class with an  iPhone   X...\n1322    no                   I did not  want  an  iPhone   X \n1323   yes           Buy   iphone   x  for me from abroad... \n1328   yes                     Need  the  iPhone   X  asap...\n1331   yes      I  need  the  iPhone   X  just for the camera\n1332    no  So disappointed with my  iPhone   X  it didn’t...\n1334    no  iPhone   X  is such a  bad  investment so  exp...\n1335   yes  My brother can go and  get  him a whole  IPhon...\n1336   yes                       iPhone   X  is sooooo pretty\n1338   yes  Y’all  need  to just go ahead and  get  this  ...\n1342    no  I wanted to say I’m more in  love  with my  iP...\n1344   yes  All I  want  for Christmas Deb Ziegler Benton ...\n1346    no  I don’t  want  the  iPhone   X  until there’s ...\n1348   yes  need  a  iphone   x  so i can take a pic for m...\n1349   yes  I’m still getting used to the  iPhone   X  lay...\n1352   yes  love  this thread but i  need  my  iphone   X ...\n\n[755 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create series of true and false. True is assigned for yes/no. False for undefine\n",
    "def Extract (path):\n",
    "    fd= open(path,encoding=\"utf-8\", errors='replace')\n",
    "    df = pd.read_csv(fd)   \n",
    "    defined=df['class'] != (\"undefined\")\n",
    "    # #output dataframe without undeined\n",
    "    df2=df[defined]\n",
    "    defined1=df2['class'] !=\"Undefined\"\n",
    "    df4=df2[defined1]\n",
    "    #replace no PI with no\n",
    "    df3=df4.replace(\"No PI\",\"no\")\n",
    "    #replace PI with yes\n",
    "    final=df3.replace(\"PI\",\"yes\")\n",
    "    \n",
    "    replace_yes=final.replace(\"Yes\",\"yes\")\n",
    "    final_df= replace_yes.replace(\"No\",\"no\")\n",
    "    return final_df, df\n",
    "\n",
    "\n",
    "path='E:/DATA/Sem8/fyp/Training.csv'\n",
    "final_df,df=Extract(path)\n",
    "# print(df['class'].value_counts())\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          class                                               text\n5     undefined  Brilliant @johnlewisretail - added  iPhone   X...\n6     undefined  They doing that on purpose cause mine is to. T...\n17    undefined                                So if I  buy  a  X \n18    undefined  Buy   iPhone   X  and  get  in the same and yo...\n21    undefined  If @Spacekatgal  didn't  get  an  iPhone   X  yet\n25    undefined  I ordered my pixel 2 on Tuesday from Google & ...\n26    undefined  Would it be the same if I  buy  an  iPhone   X...\n28    undefined  I wanna  buy  my mom a new  iPhone  so bad. I ...\n31    undefined  @ AppleSupport   I have received the  iphone  ...\n38    undefined  I  wish  I had a girl that rode for me  like  ...\n41    undefined  You look  like  you stalk the uptown event the...\n42    undefined  What you got  like  4  IPhone   X 's  buy  me ...\n46    undefined  Who  need   iphone   x  I got the direct plug ...\n51    undefined  Pre-registered customers at T World who will  ...\n54    undefined  How the hell to  get  my sugar daddy to  buy  ...\n56    undefined  If you are deciding to  buy  Apple Care + for ...\n59    undefined  I have noticed that when a new  iPhone  comes ...\n60    undefined  UPS is the WORST.  iPhone   X  is taking the P...\n61    undefined  Should I  buy   iPhone  8 Plus or wait a lil b...\n64    undefined  Apple's Animoji might not  need  the  iPhone  ...\n70    undefined  I was getting ready to  buy  the  iPhone   X  ...\n71    undefined       Day 1  w /  iPhone   X  - first impressions:\n73    undefined  God keeps sending me signs to  buy  the  iPhon...\n74    undefined  I added a video to a @YouTube  playlist  http:...\n75    undefined  Whatsup  w  all the question emojis  like  we ...\n76    undefined  Get  your santa  wish  list ready  iphone   x ...\n77    undefined  # WednesdayWisdom  YOU  NEED  TO SEE TGIS VIDE...\n78    undefined  I feel  like  this happens every time a new  i...\n81    undefined  I hate  http:// to.read    negativity towards ...\n85    undefined  If I  get  a buck for every typo I make in a t...\n...         ...                                                ...\n1286  undefined  I  wish  I knew someone who had an  iPhone   X...\n1287  undefined             Maybe  iPhone   X  is  like  a Pokémon\n1295  undefined  I don't regret it at all. Just  wish  I had wa...\n1298  undefined  ROTFLMAO! RT @selfcritics : People : why did y...\n1301  undefined  Dear @ChipotleTweets . Your new app requires m...\n1302  undefined                         you won’t give me your dog\n1304  undefined                How yall  like  yall  iphone   x ??\n1305  undefined                   When you  get  the  iPhone   X ?\n1308  undefined                 See now I'm sitting here  like .. \n1312  undefined  We  want  some stacks  like  this one for  iPh...\n1313  undefined                                  Y’all at @Apple  \n1315  undefined                   Should i  get  the  iphone   x  \n1320  undefined                                               Damn\n1321  undefined  Every time I  get  a new  iPhone  I'm always e...\n1324  undefined  But how does the home indicator work? For  iPh...\n1325  undefined  @ applesupport  my  iPhone   X  was lost by UP...\n1326  undefined            Why  iPhone   X  will  get  MR at WWDC:\n1327  undefined  So my friend has the  iPhone   X  right and i ...\n1329  undefined  tried to go  get  the  iphone   x . apparently...\n1330  undefined  Who told my mom to  get  this  iPhone   X .......\n1333  undefined  Want  a cool wallpaper for your  iPhone   X ? ...\n1337  undefined  Goodbye Verizon and your  expensive  ass payme...\n1339  undefined  So you ( like  most of us) have opted to take ...\n1340  undefined  @ andywaysworld ’s  iPhone   X  makes my 7 Plu...\n1341  undefined  The first  iPhone  came out 10 years ago. 10 y...\n1343  undefined  5 Tips to Help You  Get  the Most Out of Apple...\n1345  undefined                     iPhone   X  Diary: One week in\n1347  undefined  I have to ship my old #iPhone  back since I bo...\n1350  undefined                              If You Have A Brother\n1351  undefined  Because many things on  iPhone   X  depends on...\n\n[441 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# create series of true and false. False is assigned for yes/no. True is for undefined\n",
    "undefined=df['class'] == \"undefined\" \n",
    "#output dataframe without undeined\n",
    "df_undefine=df[undefined]\n",
    "print(df_undefine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "def read_stopwords(path):\n",
    "    file1 = open(path,\"r\") \n",
    "    stopword = file1.readlines() \n",
    "    file1.close() \n",
    "    li_stopwords = stopword[0].split()\n",
    "    return li_stopwords\n",
    "\n",
    "\n",
    "def removeStopWords(df_punc_remove):\n",
    "    # stop_words = set(stopwords.words('english')) \n",
    "    li_stopwords = read_stopwords(\"E:/DATA/Sem8/fyp/stopwords.txt\")   \n",
    "    # print(stop_words)\n",
    "    count_clean = 0\n",
    "    for text in df_punc_remove['text']:\n",
    "        word_tokens = word_tokenize(text) \n",
    "        clean_text = \"\"\n",
    "        for w in word_tokens: \n",
    "            if w.lower() not in li_stopwords: \n",
    "                if w.lower() == \"iphone\":\n",
    "                    clean_text = clean_text + w.lower()+'x'+' '\n",
    "                elif w.lower() == 'x':\n",
    "                    clean_text = clean_text\n",
    "                else: \n",
    "                    clean_text = clean_text + w.lower()+' ' \n",
    "        df_punc_remove.at[count_clean,'text'] = clean_text \n",
    "        count_clean += 1\n",
    "    #return list of corpus without stop words in a list.        \n",
    "    # print(df_punc_remove) \n",
    "    return df_punc_remove\n",
    "\n",
    "def removePunc():\n",
    "    count=0\n",
    "    punc_remove_df=pd.DataFrame()\n",
    "    for text in final_df['text']: \n",
    "        punc_remove_df.at[count,'text'] = re.sub(r'[^\\w\\s]','',text)\n",
    "        punc_remove_df.at[count,'class'] = final_df.iloc[count]['class']\n",
    "        count +=1\n",
    "    #return corpus with out punctuation.\n",
    "    # print(punc_remove_df)\n",
    "    return punc_remove_df\n",
    "\n",
    "\n",
    "\n",
    "def clean_data():\n",
    "    df_punc_remove = removePunc()\n",
    "    df_clean = removeStopWords(df_punc_remove)\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "df_cleaned_text = clean_data()\n",
    "# bprint(li_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_concat(concat_df):\n",
    "    text=\"\"\n",
    "    for x in concat_df[\"text\"]:\n",
    "        text=text +str(x)\n",
    "    return text\n",
    "\n",
    "\n",
    "text_corpus = text_concat(df_cleaned_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_vector(unique, df_clean):\n",
    "    data = np.zeros([df_clean['class'].count(), len(unique)])\n",
    "    docVector = pd.DataFrame(data,columns=unique)\n",
    "    docVector = docVector.assign(PurchaseIntention = list(df_clean['class']))\n",
    "    # docVector['Purchase Intention'] = final_df['class']\n",
    "    # print(docVector['PurchaseIntention'])\n",
    "    doc_count = 0\n",
    "    for doc in df_clean['text']:\n",
    "        words = doc.split()\n",
    "        for word in words:\n",
    "            temp=word.lower()\n",
    "            if temp in docVector.columns:\n",
    "                docVector.at[doc_count, temp] += 1\n",
    "        doc_count += 1\n",
    "        \n",
    "    return docVector\n",
    "\n",
    "\n",
    "# docVector = DocVector() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def tf_idf(corpus):\n",
    "    unique = list(set(corpus.split()))\n",
    "    # print(unique)\n",
    "    # tfIdf_df = pd.DataFrame(columns=unique)     \n",
    "    tf_df = doc_vector(unique, df_cleaned_text)\n",
    "    # idf_df = pd.DataFrame()\n",
    "    total_docs = len(tf_df.index)\n",
    "    for column in unique:\n",
    "        num_doc_word = 0\n",
    "        for no_doc in range(total_docs):\n",
    "            if tf_df.at[no_doc,column] != 0:\n",
    "                num_doc_word += 1\n",
    "        idf = math.log(total_docs/num_doc_word)\n",
    "        # idf_df.at[0,column] = idf\n",
    "        tf_df[column] = tf_df[column].multiply(idf)\n",
    "        idf = 0\n",
    "    # print(tf_df['buy'])\n",
    "    return tf_df\n",
    "    # for col in unique:\n",
    "    #     for tf_df[col]\n",
    "    # \n",
    "                \n",
    "\n",
    "df_tfIdf = tf_idf(text_corpus)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_tfIdf.iloc[0])\n",
    "# def featureExtract():\n",
    "#     total_docs = len(df_tfIdf.index)\n",
    "#     df_useful = pd.DataFrame()\n",
    "#     for doc_id in range(total_docs):\n",
    "#         doc_text = \"\"\n",
    "#         for col in df_tfIdf.columns:\n",
    "#             if col != 'PurchaseIntention':\n",
    "#                 # print(type(df_tfIdf.at[doc_id,col]))\n",
    "#                 if df_tfIdf.at[doc_id,col] > 0:\n",
    "#                     # df_useful.at[doc_id,'text'] = df_useful.at[doc_id,'text'] + col + ' '\n",
    "#                     doc_text = doc_text + col + ' '\n",
    "#         df_useful.at[doc_id,'class'] = df_tfIdf.at[doc_id,'PurchaseIntention']  \n",
    "#         df_useful.at[doc_id,'text'] = doc_text\n",
    "#     print(df_useful) \n",
    "#     return df_useful\n",
    "#     \n",
    "#  \n",
    "#     \n",
    "# df_useful = featureExtract()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def make_unique_li(li_cleanText):\n",
    "#     unique_words_set= set(li_cleanText)\n",
    "#     unique_word_li = list(unique_words_set)\n",
    "#     return unique_word_li\n",
    "# \n",
    "# \n",
    "# def stemmed(li_cleanText):\n",
    "#     count_stemed=0\n",
    "#     for word in li_cleanText:\n",
    "#         if word[-1]==\"s\":\n",
    "#             li_cleanText[count_stemed]=word[:-1]\n",
    "#         elif word[-2:]==\"ed\":\n",
    "#             li_cleanText[count_stemed]=word[:-2]\n",
    "#         elif word[-3:]==\"ing\":\n",
    "#             li_cleanText[count_stemed]=word[:-3]\n",
    "#         count_stemed+=1  \n",
    "#     return li_cleanText   \n",
    "# # li_stemmed = stemmed(li_cleaned_text)\n",
    "# uniqueWords = make_unique_li(li_cleaned_text)\n",
    "# print(uniqueWords)\n",
    "\n",
    "uniqueWords = list(set(text_corpus.split()))\n",
    "# docVector = doc_vector(uniqueWords, df_useful)\n",
    "docVector = df_tfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total PI  481\ntotal non PI  274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob pos  0.6370860927152318\nprob_neg  0.3629139072847682\n"
     ]
    }
   ],
   "source": [
    "def WordGivenNoPI(tempNegDocVector):\n",
    "    data = np.zeros([1,len(uniqueWords)])\n",
    "    wordGivenNoPI = pd.DataFrame(data,columns=uniqueWords)\n",
    "    columnSum = tempNegDocVector.sum(axis=1, skipna=True)\n",
    "    numWordsInNoPI = columnSum.sum()\n",
    "    \n",
    "    for word in uniqueWords:\n",
    "        nk_wordinNoPI = tempNegDocVector[word].sum()\n",
    "        wordGivenNoPI.at[0,word] = (nk_wordinNoPI+1) / (numWordsInNoPI+len(uniqueWords))\n",
    "    return wordGivenNoPI , numWordsInNoPI\n",
    "    \n",
    "    \n",
    "def TrainModel():\n",
    "    yesCount = docVector[\"PurchaseIntention\"] == \"yes\"\n",
    "    tempPosDocVector = docVector[yesCount]\n",
    "    totalPI = tempPosDocVector[\"PurchaseIntention\"].count()\n",
    "    print(\"total PI \",totalPI)\n",
    "    \n",
    "    noCount = docVector[\"PurchaseIntention\"] == \"no\"\n",
    "    tempNegDocVector = docVector[noCount]\n",
    "    # print(tempNegDocVector[\"PurchaseIntention\"])\n",
    "    totalNonPI = tempNegDocVector[\"PurchaseIntention\"].count()\n",
    "    print(\"total non PI \",totalNonPI)\n",
    "    # print(totalPI+totalNonPI)\n",
    "    # totalNonPI = docVector[\"PurchaseIntention\"].count() - totalPI\n",
    "    total = totalPI+totalNonPI\n",
    "    Prob_PI = totalPI/total\n",
    "    Prob_NoPI = totalNonPI/total\n",
    "    \n",
    "    data = np.zeros([1,len(uniqueWords)])\n",
    "    wordGivenPI = pd.DataFrame(data,columns=uniqueWords)\n",
    "    columnSum = tempPosDocVector.sum(axis=1, skipna=True)\n",
    "    numWordsInPI = columnSum.sum()\n",
    "    \n",
    "    for word in uniqueWords:\n",
    "        nk_wordinPI = tempPosDocVector[word].sum()\n",
    "        wordGivenPI.at[0,word] = (nk_wordinPI+1) / (numWordsInPI+len(uniqueWords))\n",
    "        \n",
    "    df_wordGivenNoPI , numWordsInNoPI = WordGivenNoPI(tempNegDocVector) \n",
    "    return (wordGivenPI,df_wordGivenNoPI,Prob_PI,Prob_NoPI,numWordsInPI,numWordsInNoPI)\n",
    "   \n",
    "\n",
    "df_WordGivenPI,df_WordGivenNoPi,Prob_PI,Prob_NoPI,numWordsInPI,numWordsInNoPI = TrainModel()\n",
    "print(\"prob pos \",Prob_PI)\n",
    "print(\"prob_neg \",Prob_NoPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      yes\n2      yes\n3      yes\n5      yes\n6      yes\n8      yes\n15     yes\n16      no\n21     yes\n23     yes\n24      no\n26     yes\n27     yes\n31     yes\n32     yes\n38     yes\n39     yes\n40     yes\n41     yes\n44     yes\n49     yes\n57      no\n60     yes\n63     yes\n65     yes\n66     yes\n67     yes\n69     yes\n70     yes\n76     yes\n      ... \n462    yes\n465    yes\n466    yes\n467    yes\n468    yes\n469    yes\n473    yes\n474    yes\n475    yes\n481    yes\n482    yes\n483    yes\n486     no\n487     no\n488    yes\n490    yes\n492    yes\n493    yes\n498    yes\n499    yes\n500    yes\n501    yes\n502    yes\n503    yes\n504    yes\n505    yes\n511    yes\n512    yes\n514    yes\n515     no\nName: class, Length: 253, dtype: object 0       no\n1      yes\n2      yes\n3       no\n4      yes\n5      yes\n6      yes\n7       no\n8      yes\n9       no\n10     yes\n11     yes\n12      no\n13      no\n14     yes\n15      no\n16     yes\n17      no\n18      no\n19     yes\n20      no\n21      no\n22     yes\n23     yes\n24     yes\n25      no\n26     yes\n27      no\n28      no\n29     yes\n      ... \n223    yes\n224     no\n225     no\n226     no\n227    yes\n228     no\n229     no\n230     no\n231     no\n232    yes\n233     no\n234     no\n235     no\n236     no\n237     no\n238     no\n239     no\n240     no\n241    yes\n242     no\n243    yes\n244    yes\n245     no\n246     no\n247    yes\n248    yes\n249    yes\n250    yes\n251     no\n252     no\nName: PredictedClass, Length: 253, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def Predict():\n",
    "    test_path=\"E:/DATA/Sem8/fyp/test data/Testing.csv\"\n",
    "    test_data,test_df = Extract(test_path)\n",
    "    # test_data = test_data.assign(PredictedClass= list(test_data['text']))\n",
    "    # test_data = test_data[['class', 'PredictedClass', 'text']]\n",
    "    # print(test_data[\"text\"].count())\n",
    "    predict_df = pd.DataFrame()\n",
    "    weighPI = Prob_PI\n",
    "    weighNoPI = Prob_NoPI\n",
    "    count_test = 0\n",
    "    for sentence in test_data['text']:\n",
    "        # print(count_test)\n",
    "        for word in sentence.lower().split():\n",
    "            if word in uniqueWords:\n",
    "                weighPI = weighPI * df_WordGivenPI.at[0,word]\n",
    "                weighNoPI = weighNoPI * df_WordGivenNoPi.at[0,word]\n",
    "            else:\n",
    "                 weighPI = weighPI * (1/(numWordsInPI+len(uniqueWords)))\n",
    "                 weighNoPI = weighNoPI * (1/(numWordsInNoPI+len(uniqueWords)))\n",
    "        predict_df.at[count_test,'WeightPI'] = weighPI    \n",
    "        if weighPI > weighNoPI:\n",
    "            predict_df.at[count_test,'PredictedClass'] = 'yes'\n",
    "            # print(test_data.at[count_test,'text'],test_data.at[count_test,'PredictedClass'])\n",
    "        else:\n",
    "           predict_df.at[count_test,'PredictedClass'] = 'no'\n",
    "           # print(test_data.at[count_test,'text'],test_data.at[count_test,'PredictedClass'])\n",
    "            \n",
    "        count_test += 1\n",
    "        weighPI = Prob_PI\n",
    "        weighNoPI = Prob_NoPI  \n",
    "    print(test_data['class'], predict_df['PredictedClass'])    \n",
    "    return predict_df, test_data  \n",
    "    \n",
    "    \n",
    "    # print(\"PI weight {0} No PI weight{1}\".format(weighPI,weighNoPI))        \n",
    "\n",
    "\n",
    "predict_df, test_data = Predict()        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 83 , FN 120, TN 38, FP 12\n"
     ]
    }
   ],
   "source": [
    "def ConfusionMatrix():\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    for i in range(test_data['class'].count()):\n",
    "        # print(test_data.iloc[i]['class'],\" \",predict_df.iloc[i]['PredictedClass'] )\n",
    "        if test_data.iloc[i]['class'] == \"yes\" and predict_df.iloc[i]['PredictedClass'] == \"yes\":\n",
    "            TP += 1\n",
    "        elif test_data.iloc[i]['class'] == \"yes\" and predict_df.iloc[i]['PredictedClass']==\"no\":\n",
    "            FN += 1\n",
    "        elif test_data.iloc[i]['class'] == \"no\" and predict_df.iloc[i]['PredictedClass']==\"no\":\n",
    "            TN += 1\n",
    "        elif test_data.iloc[i]['class'] == \"no\" and predict_df.iloc[i]['PredictedClass'] == \"yes\":\n",
    "            FP += 1    \n",
    "    return TP,FN,TN,FP\n",
    " \n",
    " \n",
    "TP,FN,TN,FP = ConfusionMatrix()\n",
    "print(\"TP {0} , FN {1}, TN {2}, FP {3}\".format(TP,FN,TN,FP))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.4505928853754941\nPrecision =  0.872093023255814\nRecall =  0.3694581280788177\nfScore =  0.5190311418685121\n"
     ]
    }
   ],
   "source": [
    "def Accuracy():\n",
    "    accuracy=(TP+TN)/(TP+FP+FN+TN)\n",
    "    # print(\"Accuracy =\",accuracy)\n",
    "    return accuracy\n",
    "   \n",
    "def Precision():\n",
    "    precision =  TP/(TP+FP)\n",
    "    # print(\"Precision = \",precision)\n",
    "    return precision\n",
    "\n",
    "def Recall():\n",
    "    recall = TP/(TP+FN)\n",
    "    # print(\"Recall = \",recall)\n",
    "    return recall\n",
    "    \n",
    "def fScore():\n",
    "    F1 = 2*(Recall() * Precision()) / (Recall() + Precision())\n",
    "    # print(\"f measure\",F1)\n",
    "    return F1\n",
    "\n",
    "\n",
    "print(\"Accuracy = \",Accuracy())\n",
    "print(\"Precision = \",Precision())\n",
    "print(\"Recall = \",Recall())\n",
    "print(\"fScore = \",fScore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # import numpy as np\n",
    "# from sklearn.metrics import roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.pyplot as plt\n",
    "# y = test_data['class']\n",
    "# scores = predict_df['WeightPI']\n",
    "# fpr, tpr, thresholds = roc_curve(y, scores, pos_label=\"yes\")\n",
    "# \n",
    "# # print(thresholds)\n",
    "# plt.plot(fpr, tpr)\n",
    "# \n",
    "# plt.show()\n",
    "\n",
    "# docVector= docVector.values\n",
    "# print(type(docVector))\n",
    "# print(docVector)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
